# machineTranslation

For the model's overall architecture, I simulate code from 

Baselines are based on different seq2seq models with pre-trained word2vec embeddings, attention mechanism, beam search strategy and Bi-directional LSTM.

![image](https://github.com/James-Le/machineTranslation/blob/master/baseline_loss.png)

![image](https://github.com/James-Le/machineTranslation/blob/master/BLEU.png)

The Dual learning model is contructed by Ruosen Li: https://github.com/lrscy/Unsupervised-Dual-Learning-Neural-Machine-Translation-Model/tree/master/pytorch-dual-learning
